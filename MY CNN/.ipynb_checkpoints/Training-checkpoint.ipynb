{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Project:\n",
    "### Based off of https://medium.com/@mjbhobe/mnist-digits-classification-with-keras-ed6c2374bd0e\n",
    "* import & set global variables\n",
    "* define load function\n",
    "* define display data function\n",
    "* load data\n",
    "* display 50 samples\n",
    "* import keras\n",
    "* define construct keras model\n",
    "* construct keras model\n",
    "* train model (split load between CPU and GPU) (is timed)\n",
    "* display loss & acuracy graphs\n",
    "* reverse one-hot and show 50 predictions compared with the true values\n",
    "* Saving & Loading the trained weights and model\n",
    "* Input image(can be any size)\n",
    "* Frontend\n",
    "* Example graphs for different Values of alpha(Adam)\n",
    "* Generated images can have random line thickness\n",
    "* image generation for filled shape case\n",
    "* cropped image as background\n",
    "* Edge detection\n",
    "* Fit shape to image size\n",
    "* list Wrong predictions for finding corelations\n",
    "* consecutive training on separate datasets\n",
    "### TO-DO:\n",
    "* generate image with resize blur\n",
    "* Autoencoder with PCA(principle component analysis(CodeParade))\n",
    "\n",
    "* Example graphs for different sized convolution kernel sizes(ex 3x3->85%, 9x9->93%,6x6->94%)(pool layers too?)\n",
    "* Example graphs for different count of input data\n",
    "* Example graphs for different epoch sizes\n",
    "* Example graphs for resized data to make it more blurry\n",
    "* Example graphs for randomised thickness of lines\n",
    "* Example graphs for filled, unfilled and mixt shapes\n",
    "\n",
    "* Slliding window for input image\n",
    "* Visualising intermediate layer output of CNN\n",
    "* Visualization of the Feature Maps Extracted\n",
    "### Tentative:\n",
    "* Remove most or all hardcoding: Image height width shape num classes class names\n",
    "* Load data in batches\n",
    "* Maybe use image segmentation but most probably does not utilise trained network\n",
    "* Check output on optical illusions(triangle made of 3 4/5 circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-Ellipse\n",
      "\n",
      "Loaded the images of dataset-Quadrilateral\n",
      "\n",
      "Loaded the images of dataset-Triangle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run commonCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "id": "Ut0nzjM1jvWw",
    "outputId": "b01fb854-04dd-4a92-a6c3-8b564e230cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying a random sample of 50 images from dataset\n"
     ]
    }
   ],
   "source": [
    "# display 50 random samples\n",
    "sample_size = 50\n",
    "print('Displaying a random sample of {} images from dataset'.format(sample_size))\n",
    "indexes = np.random.randint(0, test_images.shape[0], sample_size)\n",
    "sample_images, sample_labels = test_images[indexes], test_labels[indexes]\n",
    "display_sample(sample_images, sample_labels, sample_predictions=None, num_rows=5, num_cols=10, \n",
    "               plot_title=\"Random Sample of {} digit images\".format(sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PzcOq-yLjvXJ"
   },
   "source": [
    "# Keras Implementation\n",
    "We will develop model using Keras' Sequential API, which is much simpler to understand that the Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIyPeiwGjvXU"
   },
   "outputs": [],
   "source": [
    "#replaced keras with tensorflow.compat.v2.keras.\n",
    "# import tensorflow.compat.v2.keras.backend as K\n",
    "# from tensorflow.compat.v2.keras.models import Sequential\n",
    "# from tensorflow.compat.v2.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "# from tensorflow.compat.v2.keras import optimizers\n",
    "# import kr_helper_funcs as kru\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import kr_helper_funcs as kru\n",
    "\n",
    "# clear the Tensorflow backend to get rid of any spurious graphs\n",
    "#K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbzcXn3sjvXl"
   },
   "outputs": [],
   "source": [
    "def build_keras_model():\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=KERNEL_SIZE, padding='same', activation='relu',\n",
    "                    input_shape=IMAGE_SHAPE))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.45))\n",
    "    # output is softmax for 10 classes\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    adam = optimizers.Adam(lr=alpha)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "id": "kmjyzjV9jvXr",
    "outputId": "97ae72ba-5ed6-48fe-eb9d-17327fd07985"
   },
   "outputs": [],
   "source": [
    "kr_model = build_keras_model()\n",
    "print(kr_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1348
    },
    "colab_type": "code",
    "id": "Usc9RYLyjvX4",
    "outputId": "f0db0905-8259-45a4-84da-02479560d2a5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "%time history = kr_model.fit(X_train, y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "7Cn316JfjvYJ",
    "outputId": "ad6ddd51-9433-4f34-aac2-32339d6c92b1"
   },
   "outputs": [],
   "source": [
    "# display plots of loss & accuracies\n",
    "kru.show_plots(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "fH9kIUuSjvYS",
    "outputId": "acc8544b-56bc-4187-d680-aff5f9b8e1d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate performance against train/cross-val & test data\n",
    "print('Evaluating performance of Keras model:')\n",
    "loss, acc = kr_model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(' - Training dataset: loss = {:.4f}, accuracy = {:.4f}'.format(loss, acc))\n",
    "\n",
    "loss, acc = kr_model.evaluate(X_val, y_val, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(' - Cross-validation dataset: loss = {:.4f}, accuracy = {:.4f}'.format(loss, acc))\n",
    "\n",
    "loss, acc = kr_model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(' - Test dataset: loss = {:.4f}, accuracy = {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "kr_model.save(KR_MODEL_NAME)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = kr_model.predict(X_test)\n",
    "# reverse one-hot encode the predictions\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "# reverse one-hot encode of test data (this is the ground truth)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "#y_pred[:30]\n",
    "# count of predictions & how many incorrect predictions overall??\n",
    "len(y_pred), (y_pred != y_true).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the title of each cell shows the predicted value in green if prediction matches actual\n",
    "# else cell title shows actual/predicted value in red font\n",
    "sample_size = 50\n",
    "print('Displaying a sample of {} mistaken images from dataset'.format(sample_size))\n",
    "indexes = np.where(y_pred != y_true)[0].astype('int32')[:sample_size]\n",
    "sample_images, sample_labels, sample_predictions = test_images[indexes], test_labels[indexes], y_pred[indexes]\n",
    "display_sample(sample_images, sample_labels, sample_predictions=sample_predictions, \n",
    "               num_rows=5, num_cols=10, \n",
    "               plot_title=\"Keras - actual vs predicted - for random sample of {} images\".format(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81051"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc #garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST - CNN - Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
